---
# Plugin Info
version: 0.0.3
title: Amazon EKS
description: Log parser for Amazon EKS
parameters:
  - name: container_log_path
    label: Containers Log Path
    description: EKS Containers Log Path
    type: string
    default: "/var/log/containers/*"
  - name: kubelet_journald_log_path
    label: Kubelet Journald Log Path
    description: 'Kubernetes Kubelet Journald Log path. It will read from /run/journal or /var/log/journal if this parameter is omitted'
    type: string
  - name: cluster_name
    label: Cluster Name
    description: 'Cluster Name to be added to a resource label'
    type: string
  - name: start_at
    label: Start At
    description: "Start reading file from 'beginning' or 'end'"
    type: enum
    valid_values:
      - beginning
      - end
    default: end

# Set Defaults
# {{ $cluster_name := default "" .cluster_name }}
# {{ $container_log_path := default "/var/log/containers/*" .container_log_path }}
# {{ $start_at := default "end" .start_at }}

# Pipeline Template
pipeline:
  - id: container_reader
    type: file_input
    include:
      - '{{ $container_log_path }}'
    start_at: '{{ $start_at }}'
    labels:
      plugin_id: '{{ .id }}'
    write_to: log

  # Filter out agent logs. Check if file_name field starts with stanza or bindplane-agent.
  - id: filename_filter
    type: filter
    expr: '$labels.file_name != nil and ($labels.file_name contains "stanza" or $labels.file_name contains "bindplane-agent")'

  # Initial log entry should be safe to parse as JSON
  - id: container_json_parser
    type: json_parser
    parse_from: log

  # Attempt to parse nested JSON in log field if it exists and if JSON is detected
  - id: log_json_router
    type: router
    routes:
      # It appears to be JSON so send it to be parsed as JSON.
      - output: nested_json_parser
        expr: '$record.log != nil 